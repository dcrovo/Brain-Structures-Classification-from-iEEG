{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import math \n",
    "import sys\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from ieeg_dataset import IeegDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking uri: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = 'dIgexhE2iDrGls2qargL'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'IzEzgQpztotDnrIInJdUfUIYngpjJoT18d0FDZf7'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://localhost:9000'\n",
    "os.environ['MLFLOW_S3_IGNORE_TLS'] = 'true'\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "print('tracking uri:', mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = '../data/data_normalized_exp2'\n",
    "SEQ_LENGTH = 500\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "MODEL_DIM = 256\n",
    "NUM_HEADS = 4\n",
    "NUM_LAYERS = 4\n",
    "EXPERIMENT_NAME = \"IEEG_Classification_Architecture Search\"\n",
    "RUN_NAME = \"Transformer\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_SIZE = SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, seq_length=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "        pe = torch.zeros(seq_length, d_model)\n",
    "        position = torch.arange(0, seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, seq_length, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.positional_encoding = PositionalEncoding(model_dim, seq_length=seq_length)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        self.fc1 = nn.Linear(model_dim, model_dim // 2)\n",
    "        self.fc2 = nn.Linear(model_dim // 2, model_dim // 4)\n",
    "        self.fc3 = nn.Linear(model_dim // 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)  # Ensure x has shape [batch_size, seq_length, 1]\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=1)  # Average pooling over sequence length\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders and Partitioning\n",
    "def create_data_loaders(dataset, batch_size):\n",
    "    labels = np.array([dataset[i][1].item() for i in range(len(dataset))])\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.6, random_state=42)\n",
    "    train_index, test_index = next(sss.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "    train_dataset = Subset(dataset, train_index)\n",
    "    test_dataset = Subset(dataset, test_index)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Functions\n",
    "def plot_pie_chart(counts, class_names, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(counts, labels=class_names, autopct='%1.1f%%', startangle=90, counterclock=False)\n",
    "    ax.axis('equal')\n",
    "    plt.title(title)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, optimizer, criterion, num_epochs, device):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        y_true_train = []\n",
    "        y_pred_train = []\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move to device\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.squeeze())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clip gradients\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_train.extend(labels.squeeze().cpu().numpy())\n",
    "            y_pred_train.extend(predicted.cpu().numpy())\n",
    "\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_true_train, y_pred_train, average='weighted', zero_division=0)\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{avg_loss:.4f}',\n",
    "                'accuracy': f'{train_accuracy:.4f}',\n",
    "                'precision': f'{precision:.4f}',\n",
    "                'recall': f'{recall:.4f}',\n",
    "                'f1': f'{f1:.4f}'\n",
    "            })\n",
    "\n",
    "        mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"train_precision\", precision, step=epoch)\n",
    "        mlflow.log_metric(\"train_recall\", recall, step=epoch)\n",
    "        mlflow.log_metric(\"train_f1\", f1, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, dataset, device):\n",
    "    model.eval()\n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "    progress_bar = tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move to device\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_test.extend(labels.squeeze().cpu().numpy())\n",
    "            y_pred_test.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true_test, y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f'Accuracy of the model on the test data: {test_accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", precision)\n",
    "    mlflow.log_metric(\"test_recall\", recall)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielcrovo/Documents/01.Study/01.MSc/01.Thesis/02.AIThesis/Brain-Structures-Classification-from-iEEG/src/ieeg_dataset.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  self.data = torch.tensor(self.data, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "dataset = IeegDataset(DATA_DIR, SEQ_LENGTH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): Linear(in_features=1, out_features=256, bias=True)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, test_loader = create_data_loaders(dataset, BATCH_SIZE)\n",
    "NUM_CLASSES = len(dataset.label_encoder.classes_)\n",
    "model = TransformerModel(input_dim=1, model_dim=MODEL_DIM, num_classes=NUM_CLASSES, num_heads=NUM_HEADS, num_layers=NUM_LAYERS, seq_length=SEQ_LENGTH).to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/4', creation_time=1716522047198, experiment_id='4', last_update_time=1716522047198, lifecycle_stage='active', name='IEEG_Classification_Architecture Search', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d5793466f64256b49681e1627bc00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e11f846555492a85da0bf837ba53f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9eafcc9f5a4a5c99a981e36f08ae3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e70399efe9455cae7344331d8ebd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fcaa8f5df2419da63199b5425da0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbbe273ad0346d8a61810ea652c4f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e923c6fb16c41be8ac897da03e72a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4acd7fdcb15409981b5e20a98dfde8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882b0c54583a4b5281b1e39e4608cfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4689b743a134d8580a088d025bc9cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1538f609771540508fad70284333b3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84a1b9581b4463ea196c1e1c2f037ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7858ce7e034701a85210abfe8ba6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01f80651e1347b19492daf67c602fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c4e40e7ad846f693542e503b2a616e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62dad3f966af4833885d4deef8286597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5631a6e845848db8549d12eaf1c2bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edbc534c137493c967dd42bcb366e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311fafc654704be7afe3c8438f7d2d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1e8eef58d44b4883b2afbc62616038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b62dcc2fcd1458ba8f2e746c958db11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97284265da3b44418784e7350e760c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4031beac874764963b8e32f2b17a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d82988848f4a5695447c1fa50041e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db14b57f3ac4d4b84de8c2805cbade3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f4da3e325542fabe578d3f8dd865c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/820 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_dict(dataset\u001b[38;5;241m.\u001b[39mget_class_mapping(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_mapping.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Train and Evaluate the Model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m evaluate_model(model, test_loader, dataset, DEVICE)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Log the model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion, num_epochs, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)  \u001b[38;5;66;03m# Clip gradients\u001b[39;00m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 18\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m y_true_train\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"TransformerModel_Experiment\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", \"TransformerModel\")\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader, optimizer, criterion, NUM_EPOCHS, DEVICE)\n",
    "    evaluate_model(model, test_loader, dataset, DEVICE)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
