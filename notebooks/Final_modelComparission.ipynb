{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from cnn_tnn895 import ConvTransformerModel\n",
    "from cnn_lstm import ParallelCNNLSTMModel\n",
    "from ann_baseline import Baseline_ANN\n",
    "from cnn_lstm import  ParallelCNNLSTMModel\n",
    "from cnn_model import CNN_Ieeg_Model\n",
    "from lstm_model import LSTM_Ieeg_Model\n",
    "\n",
    "\n",
    "from utils import get_loaders_no_sss, import_checkpoint, save_checkpoint\n",
    "import torch\n",
    "import multiprocessing\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking uri: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = 'dIgexhE2iDrGls2qargL'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'IzEzgQpztotDnrIInJdUfUIYngpjJoT18d0FDZf7'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://localhost:9000'\n",
    "os.environ['MLFLOW_S3_IGNORE_TLS'] = 'true'\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\"\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "print('tracking uri:', mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = '../data/data_normalized_exp2_splited'\n",
    "DATA_DIR_EV = '../data/data_normalized_with_ev_split'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "TRAIN_DIR_EV = os.path.join(DATA_DIR_EV, 'train')\n",
    "TEST_DIR_EV = os.path.join(DATA_DIR_EV, 'test')\n",
    "class_mapping = {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
    "SEQ_LENGTH = 500\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "EXPERIMENT_NAME = \"IEEG_MODELS_COMP_FINAL_2\"\n",
    "# RUN_NAME = \"CNN\"\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "NUM_WORKERS = multiprocessing.cpu_count()\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_SIZE = SEQ_LENGTH\n",
    "NUM_CLASSES = 4\n",
    "CHECKPOINTS_PATH = '../models/checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.numel() * param.element_size()\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.numel() * buffer.element_size()\n",
    "    size_all_mb = (param_size + buffer_size) / 1024 ** 2\n",
    "    return size_all_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, optimizer: optim.Optimizer, \n",
    "                criterion: nn.Module, num_epochs: int, device: torch.device, save_checkpoint_interval: int = 10, \n",
    "                early_stopping_patience: int = 15, checkpoint_dir: str = '../models/checkpoints', \n",
    "                results_dir: str = '../models/results', accumulation_steps: int = 2,\n",
    "                cnn=False, model_name='CNN'):\n",
    "    \"\"\"\n",
    "    Train a deep learning model with the given parameters and log metrics to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        val_loader (DataLoader): DataLoader for the validation data.\n",
    "        optimizer (optim.Optimizer): Optimizer for updating model parameters.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        num_epochs (int): Number of epochs to train.\n",
    "        device (torch.device): Device to use for training (CPU or GPU).\n",
    "        save_checkpoint_interval (int, optional): Interval for saving checkpoints. Default is 10.\n",
    "        early_stopping_patience (int, optional): Patience for early stopping. Default is 15.\n",
    "        checkpoint_dir (str, optional): Directory to save checkpoints. Default is 'checkpoints'.\n",
    "        results_dir (str, optional): Directory to save results. Default is 'results'.\n",
    "        accumulation_steps (int, optional): Number of steps to accumulate gradients before updating weights. Default is 2.\n",
    "        cnn (bool, optional): If True, use CNN mode. Default is False.\n",
    "        model_name (str, optional): Name of the model for saving checkpoints. Default is 'CNN'.\n",
    "    \"\"\"\n",
    "    scaler = GradScaler()  # For mixed precision training\n",
    "    best_val_loss = float('inf')  # Track the best validation loss for early stopping\n",
    "    patience_counter = 0  # Counter for early stopping\n",
    "\n",
    "    # Ensure results and checkpoint directories exist\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    train_metrics = []\n",
    "    val_metrics = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        y_true_train = []\n",
    "        y_pred_train = []\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        optimizer.zero_grad()  # Reset gradients at the start of each epoch\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(progress_bar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with autocast():  # Mixed precision training\n",
    "                if not cnn:\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    outputs, _ = model(inputs)\n",
    "                    \n",
    "\n",
    "                loss = criterion(outputs, labels.squeeze())\n",
    "\n",
    "            scaler.scale(loss).backward()  # Backpropagation\n",
    "\n",
    "            scaler.step(optimizer)  # Update weights\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()  # Reset gradients after updating weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_train.extend(labels.squeeze().cpu().numpy())\n",
    "            y_pred_train.extend(predicted.cpu().numpy())\n",
    "\n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_true_train, y_pred_train, average='weighted', zero_division=0)\n",
    "\n",
    "            progress_bar.set_postfix(train_loss=avg_loss, train_accuracy=train_accuracy, train_precision=precision, train_recall=recall, train_f1=f1)\n",
    "\n",
    "        # Log training metrics to MLflow\n",
    "        mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"train_precision\", precision, step=epoch)\n",
    "        mlflow.log_metric(\"train_recall\", recall, step=epoch)\n",
    "        mlflow.log_metric(\"train_f1_score\", f1, step=epoch)\n",
    "\n",
    "        # Store training metrics in DataFrame\n",
    "        train_metrics.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_name\": model_name,\n",
    "            \"train_loss\": avg_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"train_precision\": precision,\n",
    "            \"train_recall\": recall,\n",
    "            \"train_f1\": f1\n",
    "        })\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_true_val = []\n",
    "        y_pred_val = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                with autocast():  # Mixed precision inference\n",
    "                    if not cnn:\n",
    "                        outputs = model(inputs)\n",
    "                    else:\n",
    "                        outputs, _ = model(inputs)\n",
    "                    loss = criterion(outputs, labels.squeeze())\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_true_val.extend(labels.squeeze().cpu().numpy())\n",
    "                y_pred_val.extend(predicted.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
    "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(y_true_val, y_pred_val, average='weighted', zero_division=0)\n",
    "\n",
    "        # Log validation metrics to MLflow\n",
    "        mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision, step=epoch)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall, step=epoch)\n",
    "        mlflow.log_metric(\"val_f1_score\", val_f1, step=epoch)\n",
    "\n",
    "        # Store validation metrics in DataFrame\n",
    "        val_metrics.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_name\": model_name,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_precision\": val_precision,\n",
    "            \"val_recall\": val_recall,\n",
    "            \"val_f1\": val_f1\n",
    "        })\n",
    "\n",
    "        # Update the progress bar with validation metrics\n",
    "        progress_bar.set_postfix(train_loss=avg_loss, train_accuracy=train_accuracy, train_precision=precision, train_recall=recall, train_f1=f1, val_loss=avg_val_loss, val_accuracy=val_accuracy, val_precision=val_precision, val_recall=val_recall, val_f1=val_f1)\n",
    "\n",
    "        # Save checkpoint every 'save_checkpoint_interval' epochs\n",
    "        if (epoch + 1) % save_checkpoint_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{model_name}.pth.tar')\n",
    "            save_checkpoint({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}, checkpoint_path)\n",
    "            mlflow.log_artifact(checkpoint_path, artifact_path=\"checkpoints\")\n",
    "\n",
    "        # Early stopping based on validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0  # Reset counter if we get a new best validation loss\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.\")\n",
    "            mlflow.log_param(f\"{model_name}_epochs_actual\", epoch + 1)\n",
    "            break\n",
    "\n",
    "        # Clear CUDA cache after each epoch\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Save training and validation metrics as CSV files\n",
    "    train_metrics_df = pd.DataFrame(train_metrics)\n",
    "    val_metrics_df = pd.DataFrame(val_metrics)\n",
    "    train_metrics_df.to_csv(os.path.join(results_dir, f'train_metrics_{model_name}.csv'), index=False)\n",
    "    val_metrics_df.to_csv(os.path.join(results_dir, f'val_metrics_{model_name}.csv'), index=False)\n",
    "\n",
    "    # Clear CUDA cache at the end of training\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(model: nn.Module, test_loader: DataLoader, class_mapping: dict, \n",
    "                   device: torch.device, img_path: str, results_dir: str,\n",
    "                   run_name: str, cnn=False, save_fm=False):\n",
    "    \"\"\"\n",
    "    Evaluate a deep learning model and log metrics to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test data.\n",
    "        class_mapping (dict): A dictionary mapping class names to class indices.\n",
    "        device (torch.device): Device to use for evaluation (CPU or GPU).\n",
    "        img_path (str): Path to save the confusion matrix image.\n",
    "        run_name (str): Name of the MLflow run.\n",
    "        batch_size (int, optional): Batch size for evaluation. Default is 16.\n",
    "        cnn (bool, optional): If True, handle model output as CNN. Default is False.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "    feature_maps = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if not cnn: \n",
    "                outputs = model(inputs)\n",
    "            else:\n",
    "                outputs, feature_map = model(inputs)\n",
    "                feature_maps.append([fm.cpu() for fm in feature_map])  # Move feature maps to CPU to free GPU memory\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_test.extend(labels.squeeze().cpu().numpy())\n",
    "            y_pred_test.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Clear cache to free up memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true_test, y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f'Accuracy of the model on the test data: {test_accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", precision)\n",
    "    mlflow.log_metric(\"test_recall\", recall)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    class_names = {v: k for k, v in class_mapping.items()}\n",
    "    cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "    cm_df = pd.DataFrame(cm, index=[class_names[i] for i in range(len(class_names))], \n",
    "                         columns=[class_names[i] for i in range(len(class_names))])\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    img_file = os.path.join(img_path, f\"confusion_matrix_{run_name}.png\")\n",
    "    cm_file = os.path.join(results_dir, f\"confusion_matrix_{run_name}.csv\")\n",
    "\n",
    "    plt.savefig(img_file)\n",
    "    cm_df.to_csv(cm_file)\n",
    "\n",
    "    mlflow.log_artifact(img_file)\n",
    "    mlflow.log_artifact(cm_file)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    # Save feature maps and labels to file\n",
    "    if save_fm:\n",
    "        feature_maps_file = os.path.join(img_path, f\"feature_maps_{run_name}.pt\")\n",
    "        torch.save((feature_maps, y_true_test, y_pred_test), feature_maps_file)\n",
    "        mlflow.log_artifact(feature_maps_file)\n",
    "\n",
    "    return y_true_test, y_pred_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN with evoked response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Train dataset size: 27165\n",
      "Test dataset size: 9480\n",
      "Train dataset length: 27165, Val dataset length: 948, Test dataset length: 8532\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, train_distribution, val_distribution, test_distribution = get_loaders_no_sss(train_dir=TRAIN_DIR_EV, test_dir=TEST_DIR_EV, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, seq_length=SEQ_LENGTH, model_type=\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Baseline_ANN(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=2000, out_features=4096, bias=True)\n",
       "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (5): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation): ReLU()\n",
       "  (output_layer): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layers = [4096,4096,2048,2048,1024,1024,512]\n",
    "model = Baseline_ANN(INPUT_SIZE, NUM_CLASSES, hidden_layers=hidden_layers, dropout=0.3).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 157.314 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'Model size: {get_model_size(model):.3f} MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/20', creation_time=1719540405626, experiment_id='20', last_update_time=1719540405626, lifecycle_stage='active', name='IEEG_MODELS_COMP_FINAL_2', tags={}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/27 22:28:21 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1471783a9227421a9a4fa2786d128843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9199ba404008499aaded2f36e3835671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1682f6b70d04438b609fdd12db0633d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b257deecf71d44769a7e9bf440eb73f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926f30090b204ec0accf1a810eae9a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b11e1f852840f8a1f8d672dabfeb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57eab334b3c9401aa0e3d51e2797fdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c42d4dbb56482c8b5781e9cee6d36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be58629b0ed54d76bdb8267696c71251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68feb6533a364bcf99ed0540668bdf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecde674f7f6432ab657984a4ba37474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6bc9798e3d4dd6a8fa501cf4e1c5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255fe98174a64076a0f008053ba925ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6855a1c89db4b54acf05cdc687d41f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229dcd050824418687e94303b3ee7adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56775d8db114446cada3b440dbacef7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0b8b0116d14134befa87bd01708e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630049b0f5c2402da9936fa5d4f81126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12618d4d4ff4a2caa37c14a61d56bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69506c0821f64b52953214959ec84875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964d4b66ee604c2eb8eaf6c978eb43d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6221e7bf024f93bd4fe3681d19726f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3bffe9e4df48548797ec11328d4d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e104f98720f44f27aa9a3c9395bfb059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb74129a9df424a8e321f9b5d99b709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688525dcee1e4ab1ba3fca6daefbc31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a445d0b3b5494808bf0da68767274a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f942aba7ae47af8446e34daedf80bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c862aac18684b438eec9696df4e36c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e46beab928c408385f233a5c98e4335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/424 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n",
      "Early stopping at epoch 30 due to no improvement in validation loss.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f609c77490a0430bb06aa8cacdad24f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/133 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.69%\n",
      "Precision: 0.6803, Recall: 0.6949, F1 Score: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/27 22:34:49 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/27 22:34:49 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"ANN_with_er_no_ss\"\n",
    "model_name = \"ANN_baseline_wr_no_ss\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    # mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=20, cnn=False)\n",
    "    _,_ = evaluate_model(model, test_loader, class_mapping, DEVICE, \n",
    "                            results_dir=results_dir,\n",
    "                            img_path='../plots', \n",
    "                            run_name=run_name,\n",
    "                            cnn=False)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Train dataset size: 21732\n",
      "Test dataset size: 8304\n",
      "Train dataset length: 21732, Val dataset length: 830, Test dataset length: 7474\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, train_distribution, val_distribution, test_distribution = get_loaders_no_sss(train_dir=TRAIN_DIR, test_dir=TEST_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, seq_length=SEQ_LENGTH, model_type=\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Baseline_ANN(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=2000, out_features=4096, bias=True)\n",
       "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (5): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation): ReLU()\n",
       "  (output_layer): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layers = [4096,4096,2048,2048,1024,1024,512]\n",
    "model = Baseline_ANN(INPUT_SIZE, NUM_CLASSES, hidden_layers=hidden_layers, dropout=0.3).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 157.314 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'Model size: {get_model_size(model):.3f} MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/20', creation_time=1719540405626, experiment_id='20', last_update_time=1719540405626, lifecycle_stage='active', name='IEEG_MODELS_COMP_FINAL_2', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/27 22:45:41 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbc85d83db04ff391874de77981e019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68b2c2095914954bdf0ad0cb8caee64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078ce087276e48c49db8c05c72cd82cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d172c13d09d348dd9f75166774f2f733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027c976bd79148359dd50574a45a992b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d1d5d8af344f048b34c52a7b45036f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8cde335d5144498fe0d246b0db5897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d3113a058848b5aea0f6c498901db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248cb452193045dab18b86f61e6e0ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7ea287081743c59bd6fa748f937a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f166c9461ed94bebb5b27fc7f2a011ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26625f70c30f42b0a846d51aeb791990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecfe8c0b605847f5b993976e1b5f8b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e902404486db482abd29b41ed2a30889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18744fb16b6d4614a0f4dfa13f25765e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84a8e38579a475d9f791efb8a6bd3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b728ebdd234aa780e3aca98bc1d554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadd5e0043d741a6be22f07304f81a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2515734e508344e48514fea6a428fe72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62fa60577f24600ac0d64e0144112de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162942a83b354c6cba86793d6df6acdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610e995005c444de9db94a3421fb1684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466915ce13f04a8694f09efda28869e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd30feb17c946a9b8d5f09bab5593b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fdcc54cb5f4114b181581761e10d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39569749ff4b4c20924ee0fbe566073b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f779b18c0143f78402f51cd6f8fc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d686a6f0d344fa8bfce187762acf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78573c9fc42c4adcb3bcb3d99d431300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b62d39ec7046b09c0bf597e41dd53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679945d65a9e42dfb0c4977c3bad9298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ed6083ab9b4ab09a98705debab0c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e5dd929db840b49509fcec02b95405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b072621ad11c46dfae2af35a4b427a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5562db8e40b4eb9a8806419cc426d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 35 due to no improvement in validation loss.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad24486f384940bc8ee1e138c12a2e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/116 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.71%\n",
      "Precision: 0.6945, Recall: 0.7113, F1 Score: 0.6920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/27 22:51:27 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/27 22:51:27 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"ANN_no_sss\"\n",
    "model_name = \"ANN_baseline_no_sss\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    # mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=20, cnn=False)\n",
    "    _,_ = evaluate_model(model, test_loader, class_mapping, DEVICE, \n",
    "                            results_dir=results_dir,\n",
    "                            img_path='../plots', \n",
    "                            run_name=run_name,\n",
    "                            cnn=False)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Train dataset size: 21732\n",
      "Test dataset size: 8304\n",
      "Train dataset length: 21732, Val dataset length: 830, Test dataset length: 7474\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, train_distribution, val_distribution, test_distribution = get_loaders_no_sss(train_dir=TRAIN_DIR, test_dir=TEST_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, seq_length=SEQ_LENGTH, model_type=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 0.09939260077305356,\n",
       "  0: 0.36333517393705134,\n",
       "  2: 0.06626173384870238,\n",
       "  3: 0.4710104914411927},\n",
       " {3: 0.40843373493975904,\n",
       "  0: 0.3686746987951807,\n",
       "  2: 0.08674698795180723,\n",
       "  1: 0.13614457831325302},\n",
       " {3: 0.4395236820979395,\n",
       "  1: 0.12938185710462938,\n",
       "  0: 0.3443938988493444,\n",
       "  2: 0.0867005619480867})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_distribution, val_distribution, test_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 252.997 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_Ieeg_Model(\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (bn_layers): ModuleList(\n",
       "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (activation): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=64000, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_Ieeg_Model(SEQ_LENGTH, NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/27 21:06:45 INFO mlflow.tracking.fluent: Experiment with name 'IEEG_MODELS_COMP_FINAL_2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/20', creation_time=1719540405626, experiment_id='20', last_update_time=1719540405626, lifecycle_stage='active', name='IEEG_MODELS_COMP_FINAL_2', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/27 21:06:55 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e350a5516a4a1689e141c8449318b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb7f433da7d423481fe9f86123e2cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2c0685f731429384c61c7e4cf85683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7835568ab84a44bc8a3a308cd569c027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97a7cdb88e146d7ae3e7e7f0776f549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c31d3ca7514da8806b746a138bbaba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff36cd9adabd4d8695d10cf16c528617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa4feb2a64f4b8a90fe3e7a868926d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967ee61be6164d678803a4026c8dbe8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7e007e9ac847f692c7981b9245ad35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d99a4ba42344188dacdbbd59e4c264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66509f3586ca434aafba13fa3c6a8630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c379e55997df44098cd2dbf372c9131d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babf8982ae5c41cf9b1619a4870ca511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6294576569614468a64c140b9d7b95c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efb4f8d29da41539f74a280992417a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78531f23ab2f4d61b209bc7ae214d9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d10540e1844c19bd9c46921267d973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8c898cc4f942e38d6d7f1fa94b0a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cfd1c1742242e4a1d2a5c49f1b90c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4887aaaa05e4b769e1ccec5fe50ced9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c125e3501e4f3299509d3c52779806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6350dd1c5e4d49a1f6149fd20ab7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba585fa46b4e4395a7e6f29786dad2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e022e3e36af84a3c8abbeb2be223d20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212b873e5dc345e186740f37002c2035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bbf9ebc56f4c098697e13c08ec251d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc14bf706afa48888400beaf13c4cf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3565c230a2af4a5a8386aa808900c0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641873146bc7423bbad4c5738ab7451f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d29e3bddde7457f9537272c74d92ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35a40ea15f245a39749d09465d6ccdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b7d3108f344d029cdd1105c4b0b812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/169 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 33 due to no improvement in validation loss.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f33dba1dd944a1d80a3bd2554f2def4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/58 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.73%\n",
      "Precision: 0.6499, Recall: 0.7256, F1 Score: 0.6486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/27 21:13:23 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/27 21:13:23 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"CNN_no_sss\"\n",
    "model_name = \"CNN_no_sss\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    # mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=20, cnn=True)\n",
    "    _,_ = evaluate_model(model, test_loader, class_mapping, DEVICE, \n",
    "                            results_dir=results_dir,\n",
    "                            img_path='../plots', \n",
    "                            run_name=run_name,\n",
    "                            cnn=True)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONV Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Train dataset size: 90550\n",
      "Test dataset size: 34600\n",
      "Train dataset length: 90550, Val dataset length: 3460, Test dataset length: 31140\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, train_distribution, val_distribution, test_distribution = get_loaders_no_sss(train_dir=TRAIN_DIR, test_dir=TEST_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, seq_length=SEQ_LENGTH, model_type=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({3: 0.4363840719332049,\n",
       "  0: 0.34858702633269106,\n",
       "  1: 0.12947976878612716,\n",
       "  2: 0.08554913294797688},\n",
       " {1: 0.09939260077305356,\n",
       "  0: 0.36333517393705134,\n",
       "  2: 0.06626173384870238,\n",
       "  3: 0.4710104914411927},\n",
       " {1: 0.1352601156069364,\n",
       "  3: 0.4367052023121387,\n",
       "  2: 0.09710982658959537,\n",
       "  0: 0.3309248554913295})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_distribution, train_distribution, val_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader - Batch 0: inputs shape = torch.Size([256, 1, 2000]), labels shape = torch.Size([256])\n",
      "test_loader - Batch 0: inputs shape = torch.Size([256, 1, 2000]), labels shape = torch.Size([256])\n",
      "val_loader - Batch 0: inputs shape = torch.Size([256, 1, 2000]), labels shape = torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for loader_name, loader in zip(['train_loader', 'test_loader','val_loader'], [train_loader, test_loader, val_loader]):\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        print(f\"{loader_name} - Batch {i}: inputs shape = {inputs.shape}, labels shape = {labels.shape}\")\n",
    "        if i == 0:  # Only print the first batch for brevity\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_size = SEQ_LENGTH  # Use the sequence length provided by your dataset\n",
    "num_classes = 4  # Number of classes for classification\n",
    "transformer_dim = 256  # Smaller transformer dimension\n",
    "num_heads = 4  # Fewer attention heads\n",
    "transformer_depth = 2  # Fewer transformer layers\n",
    "fc_neurons = [1024, 256]  # Reduced fully connected layer sizes\n",
    "fc_transformer = 128\n",
    "dropout = 0.3  # Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvTransformerModel(\n",
    "    input_size=input_size,\n",
    "    num_classes=num_classes,\n",
    "    transformer_dim=transformer_dim,\n",
    "    num_heads=num_heads,\n",
    "    transformer_depth=transformer_depth,\n",
    "    fc_neurons=fc_neurons,\n",
    "    fc_transformer=fc_transformer,\n",
    "    dropout=dropout,\n",
    "    activation=nn.GELU()\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 8.792 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvTransformerModel(\n",
       "  (conv_embedding_stem): ConvEmbeddingStem(\n",
       "    (conv1): Conv1d(1, 128, kernel_size=(10,), stride=(2,), padding=(4,), bias=False)\n",
       "    (act1): GELU(approximate='none')\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.3, inplace=False)\n",
       "    (conv2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (act2): GELU(approximate='none')\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    (conv3): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (act3): GELU(approximate='none')\n",
       "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): ModuleList(\n",
       "    (0-1): 2 x MultiheadSelfAttentionBlock(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc_transformer): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation): GELU(approximate='none')\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion =  nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/20', creation_time=1719540405626, experiment_id='20', last_update_time=1719540405626, lifecycle_stage='active', name='IEEG_MODELS_COMP_FINAL_2', tags={}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/28 00:45:18 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3c216cd3ca4ee0b60556433828df36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723cfa1fe0e34a08afe8387984160edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf77371a3984d68aaf5b09f7bc6584a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3a732c0c1e477f97119875f8f936d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c607ac4162a45acbca29fbaae68b058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b5931553414eeeb5e3783049fa4dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ce9b75a9c04a82b2884f5b8b4c8d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1712f06107854462a4e6d45177d0e8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1681627e6e4b43b8866cfd3aab5900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b27fa56a0cb42289bf3c060d13fa9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8d2cf3139347a3bfaad38a9b906774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65fdb1487d34a0494a4acfeb151a9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0979aa5f5b496fb361db15c11682f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a9d3acf7e643a0bb6c25f1036008a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c43297381f42fa8c89208688d937cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3600a74bfdf43f4bda6cc247d09d7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f67fc1aaea4c12a4311df0e15b2b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289f6e680174474ca39fc68250131a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32dac4b54324469b81317a976b5109e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f58bd94d6fc4f14ab0637597b2b8716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedb2188ac884a869cea43c0e0d08f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403525d0bb7445b8af5da90f0ba67d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5031c7c5a08440b09cc7e2cf9fe8cc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6f281b5caa4cf0802833050cef7722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3e0d97dab7447fb2485596e750b44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff2a2837e9a4f4a9a08a638d7e97fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3be1e336f242e49e83802854705468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53cb3e12cb34cb2a259f0b05999db07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdc5f9bbb494bc8b47f25da76a6fc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d321f3eb77e4d2887b546d97a469f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf3acd9e4964c63a076fe3fccf179c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70d1b70f6ca499aa5713bd971eb17cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66977a8651744ebeb7e5501b4ec52af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82157fd88e6c423e81eb83e45e21c1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6227d4bd6d4ddc918389e666a8f6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94926501fe0a4d079f94928e7eb46837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 36 due to no improvement in validation loss.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae54a5ec0ba4d0ea8446d112f7495e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.76%\n",
      "Precision: 0.7041, Recall: 0.7581, F1 Score: 0.6739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/28 01:12:09 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/28 01:12:09 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"run_CNN_TNN_sl2000_2_no_sss\"\n",
    "model_name = \"CNN_TNN_sl2000_no_sss\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    # mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=20, cnn=False)\n",
    "    _,_ = evaluate_model(model, test_loader, class_mapping, DEVICE, \n",
    "                            results_dir=results_dir,\n",
    "                            img_path='../plots', \n",
    "                            run_name=run_name,\n",
    "                            cnn=False)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Train dataset size: 90550\n",
      "Test dataset size: 34600\n",
      "Train dataset length: 90550, Val dataset length: 3460, Test dataset length: 31140\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, train_distribution, val_distribution, test_distribution = get_loaders_no_sss(train_dir=TRAIN_DIR, test_dir=TEST_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, seq_length=SEQ_LENGTH, model_type=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filters = [64, 128, 256, 512]\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 8\n",
    "dropout = 0.5\n",
    "batch_size = 256\n",
    "fc_neurons1 = 1024\n",
    "fc_neurons2 = 512\n",
    "activation = nn.GELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 81.693 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ParallelCNNLSTMModel(\n",
       "  (cnn_head): CNN_Head(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (3): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "    (bn_layers): ModuleList(\n",
       "      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation): GELU(approximate='none')\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(1, 256, num_layers=8, batch_first=True)\n",
       "  (fc_lstm): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=16000, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (activation): GELU(approximate='none')\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ParallelCNNLSTMModel(\n",
    "            input_size=SEQ_LENGTH,\n",
    "            input_size_lstm=1,\n",
    "            num_classes=4,\n",
    "            conv_filters=conv_filters,\n",
    "            lstm_hidden_size=lstm_hidden_size,\n",
    "            lstm_num_layers=lstm_num_layers,\n",
    "            fc_neurons=[fc_neurons1, fc_neurons2],\n",
    "            dropout=dropout,\n",
    "            activation=activation\n",
    "        ).to(DEVICE)\n",
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion =  nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "    if experiment.lifecycle_stage == 'deleted':\n",
    "        mlflow.tracking.MlflowClient().restore_experiment(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/20', creation_time=1719540405626, experiment_id='20', last_update_time=1719540405626, lifecycle_stage='active', name='IEEG_MODELS_COMP_FINAL_2', tags={}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/28 01:47:22 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262ba6cd4a9e4e93a19cc66d525041d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/353 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/28 01:47:45 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/28 01:47:45 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m, NUM_CLASSES)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Train and Evaluate the Model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_checkpoint_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHECKPOINTS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m _,_ \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, class_mapping, DEVICE, \n\u001b[1;32m     20\u001b[0m                         results_dir\u001b[38;5;241m=\u001b[39mresults_dir,\n\u001b[1;32m     21\u001b[0m                         img_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../plots\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     22\u001b[0m                         run_name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m     23\u001b[0m                         cnn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Log the model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 52\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, num_epochs, device, save_checkpoint_interval, early_stopping_patience, checkpoint_dir, results_dir, accumulation_steps, cnn, model_name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():  \u001b[38;5;66;03m# Mixed precision training\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cnn:\n\u001b[0;32m---> 52\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m         outputs, _ \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/01.Study/01.MSc/01.Thesis/02.AIThesis/Brain-Structures-Classification-from-iEEG/src/cnn_lstm.py:143\u001b[0m, in \u001b[0;36mParallelCNNLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    140\u001b[0m x_cnn \u001b[38;5;241m=\u001b[39m x_cnn\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten for concatenation\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# LSTM path\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m x_lstm, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust shape for LSTM\u001b[39;00m\n\u001b[1;32m    144\u001b[0m x_lstm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_lstm(x_lstm[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Take the last output of LSTM\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Concatenate CNN and LSTM outputs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:911\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    908\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    915\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"P_CNN_LSTM_no_sss_2000\"\n",
    "model_name = \"P_CNN_LSTM_no_sss_2000\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    # mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=20, cnn=False)\n",
    "    _,_ = evaluate_model(model, test_loader, class_mapping, DEVICE, \n",
    "                            results_dir=results_dir,\n",
    "                            img_path='../plots', \n",
    "                            run_name=run_name,\n",
    "                            cnn=False)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Applying this mapping: {'CA': 0, 'CA1': 1, 'Thalamus': 2, 'vM1': 3}\n",
      "Train dataset size: 21732\n",
      "Test dataset size: 8304\n",
      "Train dataset length: 21732, Val dataset length: 830, Test dataset length: 7474\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, train_distribution, val_distribution, test_distribution = get_loaders_no_sss(train_dir=TRAIN_DIR, test_dir=TEST_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, seq_length=SEQ_LENGTH, model_type=\"seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader - Batch 0: inputs shape = torch.Size([64, 2000, 1]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 0: inputs shape = torch.Size([64, 2000, 1]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 0: inputs shape = torch.Size([64, 2000, 1]), labels shape = torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for loader_name, loader in zip(['train_loader', 'test_loader','val_loader'], [train_loader, test_loader, val_loader]):\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        print(f\"{loader_name} - Batch {i}: inputs shape = {inputs.shape}, labels shape = {labels.shape}\")\n",
    "        if i == 0:  # Only print the first batch for brevity\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5.292 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM_Ieeg_Model(\n",
       "  (activation): ReLU()\n",
       "  (lstm): LSTM(1, 128, num_layers=8, batch_first=True, dropout=0.1)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_Ieeg_Model(device=DEVICE,\n",
    "                        input_size=1, \n",
    "                        num_classes=NUM_CLASSES, \n",
    "                        lstm_layers=8, \n",
    "                        lstm_h_size=128,\n",
    "                        fc_neurons=[1024,256], \n",
    "                        bidirectional=False).to(DEVICE)\n",
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion =  nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/20', creation_time=1719540405626, experiment_id='20', last_update_time=1719540405626, lifecycle_stage='active', name='IEEG_MODELS_COMP_FINAL_2', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/27 21:35:33 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7758a2aadb4787b15e23e0d05dd498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5f1895e7414d878ce03bee07b32f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80f3b57640647c89e0121db955707a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941b4bd3462640b9975d9af5d1d803f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37771ea029e24dcaab6ccde7bb4f8dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc710bcdff884cd394e96e2047101cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3a755e493c4695a61991516dd67f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9db7d7509f414dbc8945168763622c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4636db3ee26b4fabaf4212ec28aac47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02927c1a6f9c4853a5d51d74f8fd4100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1a18608b284f2781689709a5b1de87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a84ddf712340f6b97d9990af7511a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c638cf95402479cb9735046168c77c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbcf077124d4f8d9c1b117af47d389c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4462a9dcaf2f4308bb22908c4caafb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbfba6a98894ac1a9e8fca397cfe5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d448b60d404d959ba33a5a5b9d336a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2dc0a5bc93743da9cb7c2657ec08d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf000deedf84a298f533567bc7740ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300bd32942b74c309f625602c3c0847b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cbfa57131b4bf6827176fa8959f098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49a646e14c2422f9702cde9c662d568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc17b4794c643c786f0774e2959a757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5348b7986e684b9982da52c3e3e2a383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a19080998f4d548c9551d81f7b03f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/339 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25 due to no improvement in validation loss.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49f65db7c86455187bea1c71d19b271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/116 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.44%\n",
      "Precision: 0.1912, Recall: 0.4372, F1 Score: 0.2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/27 21:58:43 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/27 21:58:43 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "run_name = \"run_LSTM_2000_no_sss\"\n",
    "model_name = \"LSTM_2000_no_sss\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    # mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=20, cnn=False)\n",
    "    _,_ = evaluate_model(model, test_loader, class_mapping, DEVICE, \n",
    "                            results_dir=results_dir,\n",
    "                            img_path='../plots', \n",
    "                            run_name=run_name,\n",
    "                            cnn=False)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
