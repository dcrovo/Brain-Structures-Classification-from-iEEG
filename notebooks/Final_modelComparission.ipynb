{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from conv_transformer import ConvTransformerModel\n",
    "from cnn_lstm import ParallelCNNLSTMModel\n",
    "from utils import get_loaders, import_checkpoint, save_checkpoint\n",
    "import torch\n",
    "import multiprocessing\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking uri: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = 'dIgexhE2iDrGls2qargL'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'IzEzgQpztotDnrIInJdUfUIYngpjJoT18d0FDZf7'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://localhost:9000'\n",
    "os.environ['MLFLOW_S3_IGNORE_TLS'] = 'true'\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\"\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "print('tracking uri:', mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = '../data/data_normalized_exp2'\n",
    "SEQ_LENGTH = 500\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "EXPERIMENT_NAME = \"IEEG_Classification_Final_Comp\"\n",
    "# RUN_NAME = \"CNN\"\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "NUM_WORKERS = multiprocessing.cpu_count()\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_SIZE = SEQ_LENGTH\n",
    "NUM_CLASSES = 5\n",
    "CHECKPOINTS_PATH = '../models/checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.numel() * param.element_size()\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.numel() * buffer.element_size()\n",
    "    size_all_mb = (param_size + buffer_size) / 1024 ** 2\n",
    "    return size_all_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, optimizer: optim.Optimizer, \n",
    "                criterion: nn.Module, num_epochs: int, device: torch.device, save_checkpoint_interval: int = 10, \n",
    "                early_stopping_patience: int = 15, checkpoint_dir: str = '../models/checkpoints', accumulation_steps: int = 2,\n",
    "                cnn=False, model_name='CNN'):\n",
    "    \"\"\"\n",
    "    Train a deep learning model with the given parameters and log metrics to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        val_loader (DataLoader): DataLoader for the validation data.\n",
    "        optimizer (optim.Optimizer): Optimizer for updating model parameters.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        num_epochs (int): Number of epochs to train.\n",
    "        device (torch.device): Device to use for training (CPU or GPU).\n",
    "        save_checkpoint_interval (int, optional): Interval for saving checkpoints. Default is 10.\n",
    "        early_stopping_patience (int, optional): Patience for early stopping. Default is 15.\n",
    "        checkpoint_dir (str, optional): Directory to save checkpoints. Default is 'checkpoints'.\n",
    "        accumulation_steps (int, optional): Number of steps to accumulate gradients before updating weights. Default is 2.\n",
    "        cnn (bool, optional): If True, use CNN mode. Default is False.\n",
    "        model_name (str, optional): Name of the model for saving checkpoints. Default is 'CNN'.\n",
    "    \"\"\"\n",
    "    scaler = GradScaler()  # For mixed precision training\n",
    "    best_val_loss = float('inf')  # Track the best validation loss for early stopping\n",
    "    patience_counter = 0  # Counter for early stopping\n",
    "\n",
    "    # Ensure checkpoint directory exists\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        y_true_train = []\n",
    "        y_pred_train = []\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        optimizer.zero_grad()  # Reset gradients at the start of each epoch\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(progress_bar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with autocast():  # Mixed precision training\n",
    "                if not cnn:\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    outputs, _ = model(inputs)\n",
    "                loss = criterion(outputs, labels.squeeze())\n",
    "\n",
    "            scaler.scale(loss).backward()  # Backpropagation\n",
    "\n",
    "            scaler.step(optimizer)  # Update weights\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()  # Reset gradients after updating weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_train.extend(labels.squeeze().cpu().numpy())\n",
    "            y_pred_train.extend(predicted.cpu().numpy())\n",
    "\n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_true_train, y_pred_train, average='weighted', zero_division=0)\n",
    "\n",
    "            progress_bar.set_postfix(train_loss=avg_loss, train_accuracy=train_accuracy, train_precision=precision, train_recall=recall, train_f1=f1)\n",
    "\n",
    "        # Log training metrics to MLflow\n",
    "        mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"train_precision\", precision, step=epoch)\n",
    "        mlflow.log_metric(\"train_recall\", recall, step=epoch)\n",
    "        mlflow.log_metric(\"train_f1\", f1, step=epoch)\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_true_val = []\n",
    "        y_pred_val = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                with autocast():  # Mixed precision inference\n",
    "                    if not cnn:\n",
    "                        outputs = model(inputs)\n",
    "                    else:\n",
    "                        outputs, _ = model(inputs)\n",
    "                    loss = criterion(outputs, labels.squeeze())\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_true_val.extend(labels.squeeze().cpu().numpy())\n",
    "                y_pred_val.extend(predicted.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
    "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(y_true_val, y_pred_val, average='weighted', zero_division=0)\n",
    "\n",
    "        # Log validation metrics to MLflow\n",
    "        mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision, step=epoch)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall, step=epoch)\n",
    "        mlflow.log_metric(\"val_f1\", val_f1, step=epoch)\n",
    "\n",
    "        # Update the progress bar with validation metrics\n",
    "        progress_bar.set_postfix(train_loss=avg_loss, train_accuracy=train_accuracy, train_precision=precision, train_recall=recall, train_f1=f1, val_loss=avg_val_loss, val_accuracy=val_accuracy, val_precision=val_precision, val_recall=val_recall, val_f1=val_f1)\n",
    "\n",
    "        # Save checkpoint every 'save_checkpoint_interval' epochs\n",
    "        if (epoch + 1) % save_checkpoint_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{model_name}.pth.tar')\n",
    "            save_checkpoint({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}, checkpoint_path)\n",
    "            mlflow.log_artifact(checkpoint_path, artifact_path=\"checkpoints\")\n",
    "\n",
    "        # Early stopping based on validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0  # Reset counter if we get a new best validation loss\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.\")\n",
    "            mlflow.log_param(\"epochs_actual\", epoch + 1)\n",
    "            break\n",
    "\n",
    "        # Clear CUDA cache after each epoch\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Clear CUDA cache at the end of training\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model: nn.Module, test_loader: DataLoader, dataset: Dataset, device: torch.device, \n",
    "                   img_path: str, run_name: str, batch_size: int = 16, cnn=False):\n",
    "    \"\"\"\n",
    "    Evaluate a deep learning model and log metrics to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test data.\n",
    "        dataset (Dataset): The dataset containing the test data.\n",
    "        device (torch.device): Device to use for evaluation (CPU or GPU).\n",
    "        img_path (str): Path to save the confusion matrix image.\n",
    "        run_name (str): Name of the MLflow run.\n",
    "        batch_size (int, optional): Batch size for evaluation. Default is 16.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "    feature_maps = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if not cnn: \n",
    "                outputs = model(inputs)\n",
    "\n",
    "            else:\n",
    "                outputs, feature_map = model(inputs)\n",
    "                feature_maps.append([fm.cpu() for fm in feature_map])  # Move feature maps to CPU to free GPU memory\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_test.extend(labels.squeeze().cpu().numpy())\n",
    "            y_pred_test.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Clear cache to free up memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true_test, y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f'Accuracy of the model on the test data: {test_accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", precision)\n",
    "    mlflow.log_metric(\"test_recall\", recall)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "    cm_df = pd.DataFrame(cm, index=dataset.label_encoder.classes_, columns=dataset.label_encoder.classes_)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    img_file = os.path.join(img_path, f\"confusion_matrix_{run_name}.png\")\n",
    "    plt.savefig(img_file)\n",
    "    mlflow.log_artifact(img_file)\n",
    "    plt.close()\n",
    "\n",
    "    # Save feature maps and labels to file\n",
    "    if cnn:\n",
    "        feature_maps_file = os.path.join(img_path, f\"feature_maps_{run_name}.pt\")\n",
    "        torch.save((feature_maps, y_true_test, y_pred_test), feature_maps_file)\n",
    "    # mlflow.log_artifact(feature_maps_file, artifact_path=\"feature_maps\")\n",
    "\n",
    "    return y_true_test, y_pred_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONV Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 131150\n",
      "Train indices length: 118035, Test indices length: 13115\n",
      "Train indices after val split: 106231, Val indices: 11804\n",
      "Train dataset length: 106231, Val dataset length: 11804, Test dataset length: 13115\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, dataset = get_loaders(data_dir=DATA_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, test_size=0.1, seq_length=SEQ_LENGTH, model_type=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader - Batch 0: inputs shape = torch.Size([64, 1, 500]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 0: inputs shape = torch.Size([64, 1, 500]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 0: inputs shape = torch.Size([64, 1, 500]), labels shape = torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for loader_name, loader in zip(['train_loader', 'test_loader','val_loader'], [train_loader, test_loader, val_loader]):\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        print(f\"{loader_name} - Batch {i}: inputs shape = {inputs.shape}, labels shape = {labels.shape}\")\n",
    "        if i == 0:  # Only print the first batch for brevity\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_size = SEQ_LENGTH  # Use the sequence length provided by your dataset\n",
    "num_classes = 5  # Number of classes for classification\n",
    "conv_filters = [64, 128]  # Reduced number of filters to save memory\n",
    "transformer_dim = 128  # Smaller transformer dimension\n",
    "num_heads = 4  # Fewer attention heads\n",
    "transformer_depth = 2  # Fewer transformer layers\n",
    "fc_neurons = [512, 128]  # Reduced fully connected layer sizes\n",
    "dropout = 0.3  # Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvTransformerModel(\n",
    "    input_size=input_size,\n",
    "    num_classes=num_classes,\n",
    "    transformer_dim=transformer_dim,\n",
    "    num_heads=num_heads,\n",
    "    transformer_depth=transformer_depth,\n",
    "    fc_neurons=fc_neurons,\n",
    "    dropout=dropout,\n",
    "    activation=nn.ReLU()\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 2.365 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvTransformerModel(\n",
       "  (conv_embedding_stem): ConvEmbeddingStem(\n",
       "    (conv1): Conv1d(1, 64, kernel_size=(10,), stride=(2,), padding=(4,), bias=False)\n",
       "    (act1): GELU(approximate='none')\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (act2): GELU(approximate='none')\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (act3): GELU(approximate='none')\n",
       "    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (transformer_blocks): ModuleList(\n",
       "    (0-1): 2 x MultiheadSelfAttentionBlock(\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc_transformer): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion =  nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/11', creation_time=1716942946817, experiment_id='11', last_update_time=1716942946817, lifecycle_stage='active', name='IEEG_Classification_Final_Comp', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/29 01:27:23 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1b463eeea74f4fa881117553b1b9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97997c4cd7cd41e099681d03cebbddb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487e93d98c2745798e24715703402299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8089ed68e2b840a5bd2ce4234dfcf72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35349036a8564ee1980661910f8d6333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d6874d99114d9bb7555c826ded2c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d007766add924e5d89afd648a0f55b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3431c767efb441f8493197d7e0d3a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0520390bb8f4f6cbfb3d43c6d65f988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6156edcd19e4076ad9411b90b67e213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31a648e070d4560827d8eb390a9854d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bf0c4bb48e455090b1863cb3b93b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fd8f2002fd4189adcbcfeab0ce62da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e255eadf485644d3bd8058326d8ef9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b264087e3ee445f872e1bbd149ef28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582871efab2c462685c784b961bb4f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e989c939964cd882d004a146b328c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f680a4f6de84488a8ffbbfea926dd155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9151024aefb04fc0adc3d9866a091469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d671f9aa95343429beace79eeb249b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802bc14f3d9d4d0f96e4d115627fe768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94536317699e482687995fcfa921008b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7bd490ba4f44839d112e7e922f93a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6b34673c554aa1af93876031ac748e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328e92b1c8b24f528e76f1c27dfcadc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6052638a15854bd090d79848d17812ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f913e1f618a46f9b5ad4d9ba9393396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3058dd1bc66c42b08dab01e2006d6fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace88a1afe10446e90d2a783bff2df02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7545cc4fa6d74f32a2c43bba691f359e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fbd7f43bba4308902f5fea6c689a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434fdad3860747928af727cfd70a5dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9819930c61248368ce418810208225b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f6b99c2aeb4e239320c62926c9f7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff62798b18b4850a4247d0c10c17648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef270a77610047d788f2f76cf175fc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4990ffef97e24450a70f7081e7aca1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f867af4163ad434aab015a900a3e9373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ba44176ee34b1c826c4d392701c9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c4cf69e87a421fbdb7574d3a1b34c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3a8a3ed8c24099be85afd26a074eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692de89bf1394678b7707010593e44d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1895d14f5e954a77ace47ae624a5bec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a478faf9aec4d74b283a7b164be3fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1eb43fcf6c94b48b572b5b6bd712bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60db3697959d41ee82f3721785e95b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb56e5eeef043df9c8b4ba1255cbe81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719d791f486743a3882cba1c4c9ea418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e968edd316443aa2929f0a7cd7d0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadc98ac84a8456284c13f104f7c14b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154a27156fbd487196f4e2d4ebd555f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/205 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.97%\n",
      "Precision: 0.9701, Recall: 0.9706, F1 Score: 0.9703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/29 02:42:04 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/05/29 02:42:04 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"CONV_Transformer_sl500\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", \"Conv_Tranformer_sl500\")\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=\"Conv_Tranformer_sl500\", early_stopping_patience=40, cnn=False)\n",
    "    evaluate_model(model, test_loader, dataset, DEVICE, img_path='../plots', run_name=run_name)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, \"model_Conv_Tranformer_sl500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 131150\n",
      "Train indices length: 118035, Test indices length: 13115\n",
      "Train indices after val split: 106231, Val indices: 11804\n",
      "Train dataset length: 106231, Val dataset length: 11804, Test dataset length: 13115\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, dataset = get_loaders(data_dir=DATA_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, test_size=0.1, seq_length=SEQ_LENGTH, model_type=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 65.849 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ParallelCNNLSTMModel(\n",
       "  (cnn_head): CNN_Head(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (3): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "    (bn_layers): ModuleList(\n",
       "      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(1, 64, num_layers=3, batch_first=True)\n",
       "  (fc_lstm): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=16000, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ParallelCNNLSTMModel(input_size=SEQ_LENGTH, \n",
    "                            num_classes=NUM_CLASSES,\n",
    "                            input_size_lstm=1,\n",
    "                            # conv_filters=[64,128,256],\n",
    "                            # fc_neurons=[1024,128],\n",
    "                            # lstm_hidden_size=64,\n",
    "                            lstm_num_layers=3\n",
    "                        ).to(DEVICE)\n",
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion =  nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "    if experiment.lifecycle_stage == 'deleted':\n",
    "        mlflow.tracking.MlflowClient().restore_experiment(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/11', creation_time=1716942946817, experiment_id='11', last_update_time=1716942946817, lifecycle_stage='active', name='IEEG_Classification_Final_Comp', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/29 10:36:59 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74735c73f0f4828908fd98544a84748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8740075d50064860ac688f65d6cfb3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5c2ac335164c33a96efcbf3a3c2330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18026fdc02d14270b707efcf32eb4199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787e8a1938da4c0d8e31453e8fbdbd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a0dd65e1cb4ec3880cc160458c2a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715a6ad6503946ebaf8a7bd7b32ece61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d5cb789f5f469f81bf3bc4b220afcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44a0db8e4544b3a856841ed507f6d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf924a54c114651a22d63301545c7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657cf9d1a55a4982a7bd9a8180167a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81c0ee739364309b43b758588c3bdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25e4856a7b646f0816ce7320114417a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d8ac00f2eb4134ad0b2096c8f0cf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a27e35f7bb84df78ce6ade99f6735b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526adcc6648b45679e65f5470129abec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0a67ae147849a08264c76ac171cce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b60e8d31d2464b920997395a614908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1157448b77a84a7589170f3dc7df3e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1c826f1b3b4ebcbee9353ea969adcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc9718073c4410292ac26b90c35c83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00cb10131334dfda2f15eecc7d6b563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0001cf3ee1442bf953126f4df9bf2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f24bcbe0fb447e189be5c69d629eef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35ddbd342e54c7b83c85194de18f6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7f4e1e67504528a1085a8281de5959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6282bdef7446dc833c9f50908f8376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00129ffb538c4547af82be27df668fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dcc4bdcda9425ab556b733358fabf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605f4a0afd6c4574a8d017b1161205a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d775a39822ef4cf48510ceb85498afe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f4fe8fdcdb452d9738aec9508ec0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fc7aabe00d45cebbc0c7d6887b1a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/1660 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 33 due to no improvement in validation loss.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3253e1e690684bd8ae1fb868772f948f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/205 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.96%\n",
      "Precision: 0.9603, Recall: 0.9606, F1 Score: 0.9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/29 11:26:56 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/05/29 11:26:56 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"P_CNN_LSTM_Experiment_sl500\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", \"P_CNN_LSTM_sl500\")\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader, val_loader,optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=\"P_CNN_LSTM_sl500\", early_stopping_patience=15, cnn=False)\n",
    "    evaluate_model(model, test_loader, dataset, DEVICE, img_path='../plots', run_name=run_name)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, \"model_P_CNN_LSTM_sl500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
