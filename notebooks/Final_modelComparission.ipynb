{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from conv_transformer import ConvTransformerModel\n",
    "from cnn_lstm import ParallelCNNLSTMModel\n",
    "from ann_baseline import Baseline_ANN\n",
    "from cnn_lstm import CNN_LSTM_Model, ParallelCNNLSTMModel, LSTM_CNN,ParallelCNNTransformerModel\n",
    "from cnn_model import CNN_Ieeg_Model\n",
    "from lstm_model import LSTM_Ieeg_Model\n",
    "\n",
    "\n",
    "from utils import get_loaders, import_checkpoint, save_checkpoint\n",
    "import torch\n",
    "import multiprocessing\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking uri: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = 'dIgexhE2iDrGls2qargL'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'IzEzgQpztotDnrIInJdUfUIYngpjJoT18d0FDZf7'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://localhost:9000'\n",
    "os.environ['MLFLOW_S3_IGNORE_TLS'] = 'true'\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\"\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "print('tracking uri:', mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = '../data/data_normalized_exp2'\n",
    "DATA_DIR_EV = '../data/data_normalized_with_ev'\n",
    "\n",
    "SEQ_LENGTH = 300\n",
    "BATCH_SIZE = 200\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "EXPERIMENT_NAME = \"SECOND_IEEG_MODELS_COMP_FINAL\"\n",
    "# RUN_NAME = \"CNN\"\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "NUM_WORKERS = multiprocessing.cpu_count()\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_SIZE = SEQ_LENGTH\n",
    "NUM_CLASSES = 4\n",
    "CHECKPOINTS_PATH = '../models/checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.numel() * param.element_size()\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.numel() * buffer.element_size()\n",
    "    size_all_mb = (param_size + buffer_size) / 1024 ** 2\n",
    "    return size_all_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, optimizer: optim.Optimizer, \n",
    "                criterion: nn.Module, num_epochs: int, device: torch.device, save_checkpoint_interval: int = 10, \n",
    "                early_stopping_patience: int = 15, checkpoint_dir: str = '../models/checkpoints', \n",
    "                results_dir: str = '../models/results', accumulation_steps: int = 2,\n",
    "                cnn=False, model_name='CNN'):\n",
    "    \"\"\"\n",
    "    Train a deep learning model with the given parameters and log metrics to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        val_loader (DataLoader): DataLoader for the validation data.\n",
    "        optimizer (optim.Optimizer): Optimizer for updating model parameters.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        num_epochs (int): Number of epochs to train.\n",
    "        device (torch.device): Device to use for training (CPU or GPU).\n",
    "        save_checkpoint_interval (int, optional): Interval for saving checkpoints. Default is 10.\n",
    "        early_stopping_patience (int, optional): Patience for early stopping. Default is 15.\n",
    "        checkpoint_dir (str, optional): Directory to save checkpoints. Default is 'checkpoints'.\n",
    "        results_dir (str, optional): Directory to save results. Default is 'results'.\n",
    "        accumulation_steps (int, optional): Number of steps to accumulate gradients before updating weights. Default is 2.\n",
    "        cnn (bool, optional): If True, use CNN mode. Default is False.\n",
    "        model_name (str, optional): Name of the model for saving checkpoints. Default is 'CNN'.\n",
    "    \"\"\"\n",
    "    scaler = GradScaler()  # For mixed precision training\n",
    "    best_val_loss = float('inf')  # Track the best validation loss for early stopping\n",
    "    patience_counter = 0  # Counter for early stopping\n",
    "\n",
    "    # Ensure results and checkpoint directories exist\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    train_metrics = []\n",
    "    val_metrics = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        y_true_train = []\n",
    "        y_pred_train = []\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        optimizer.zero_grad()  # Reset gradients at the start of each epoch\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(progress_bar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with autocast():  # Mixed precision training\n",
    "                if not cnn:\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    outputs, _ = model(inputs)\n",
    "                    \n",
    "\n",
    "                loss = criterion(outputs, labels.squeeze())\n",
    "\n",
    "            scaler.scale(loss).backward()  # Backpropagation\n",
    "\n",
    "            scaler.step(optimizer)  # Update weights\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()  # Reset gradients after updating weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_train.extend(labels.squeeze().cpu().numpy())\n",
    "            y_pred_train.extend(predicted.cpu().numpy())\n",
    "\n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_true_train, y_pred_train, average='weighted', zero_division=0)\n",
    "\n",
    "            progress_bar.set_postfix(train_loss=avg_loss, train_accuracy=train_accuracy, train_precision=precision, train_recall=recall, train_f1=f1)\n",
    "\n",
    "        # Log training metrics to MLflow\n",
    "        mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"train_precision\", precision, step=epoch)\n",
    "        mlflow.log_metric(\"train_recall\", recall, step=epoch)\n",
    "        mlflow.log_metric(\"train_f1_score\", f1, step=epoch)\n",
    "\n",
    "        # Store training metrics in DataFrame\n",
    "        train_metrics.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_name\": model_name,\n",
    "            \"train_loss\": avg_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"train_precision\": precision,\n",
    "            \"train_recall\": recall,\n",
    "            \"train_f1\": f1\n",
    "        })\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_true_val = []\n",
    "        y_pred_val = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                with autocast():  # Mixed precision inference\n",
    "                    if not cnn:\n",
    "                        outputs = model(inputs)\n",
    "                    else:\n",
    "                        outputs, _ = model(inputs)\n",
    "                    loss = criterion(outputs, labels.squeeze())\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_true_val.extend(labels.squeeze().cpu().numpy())\n",
    "                y_pred_val.extend(predicted.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
    "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(y_true_val, y_pred_val, average='weighted', zero_division=0)\n",
    "\n",
    "        # Log validation metrics to MLflow\n",
    "        mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision, step=epoch)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall, step=epoch)\n",
    "        mlflow.log_metric(\"val_f1_score\", val_f1, step=epoch)\n",
    "\n",
    "        # Store validation metrics in DataFrame\n",
    "        val_metrics.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_name\": model_name,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_precision\": val_precision,\n",
    "            \"val_recall\": val_recall,\n",
    "            \"val_f1\": val_f1\n",
    "        })\n",
    "\n",
    "        # Update the progress bar with validation metrics\n",
    "        progress_bar.set_postfix(train_loss=avg_loss, train_accuracy=train_accuracy, train_precision=precision, train_recall=recall, train_f1=f1, val_loss=avg_val_loss, val_accuracy=val_accuracy, val_precision=val_precision, val_recall=val_recall, val_f1=val_f1)\n",
    "\n",
    "        # Save checkpoint every 'save_checkpoint_interval' epochs\n",
    "        if (epoch + 1) % save_checkpoint_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{model_name}.pth.tar')\n",
    "            save_checkpoint({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}, checkpoint_path)\n",
    "            mlflow.log_artifact(checkpoint_path, artifact_path=\"checkpoints\")\n",
    "\n",
    "        # Early stopping based on validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0  # Reset counter if we get a new best validation loss\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.\")\n",
    "            mlflow.log_param(f\"{model_name}_epochs_actual\", epoch + 1)\n",
    "            break\n",
    "\n",
    "        # Clear CUDA cache after each epoch\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Save training and validation metrics as CSV files\n",
    "    train_metrics_df = pd.DataFrame(train_metrics)\n",
    "    val_metrics_df = pd.DataFrame(val_metrics)\n",
    "    train_metrics_df.to_csv(os.path.join(results_dir, f'train_metrics_{model_name}.csv'), index=False)\n",
    "    val_metrics_df.to_csv(os.path.join(results_dir, f'val_metrics_{model_name}.csv'), index=False)\n",
    "\n",
    "    # Clear CUDA cache at the end of training\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model: nn.Module, test_loader: DataLoader, dataset: Dataset, \n",
    "                   device: torch.device, img_path: str, results_dir: str,\n",
    "                   run_name: str, batch_size: int = 16, cnn=False):\n",
    "    \"\"\"\n",
    "    Evaluate a deep learning model and log metrics to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test data.\n",
    "        dataset (Dataset): The dataset containing the test data.\n",
    "        device (torch.device): Device to use for evaluation (CPU or GPU).\n",
    "        img_path (str): Path to save the confusion matrix image.\n",
    "        run_name (str): Name of the MLflow run.\n",
    "        batch_size (int, optional): Batch size for evaluation. Default is 16.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "    feature_maps = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if not cnn: \n",
    "                outputs = model(inputs)\n",
    "\n",
    "            else:\n",
    "                outputs, feature_map = model(inputs)\n",
    "                feature_maps.append([fm.cpu() for fm in feature_map])  # Move feature maps to CPU to free GPU memory\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_test.extend(labels.squeeze().cpu().numpy())\n",
    "            y_pred_test.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Clear cache to free up memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true_test, y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f'Accuracy of the model on the test data: {test_accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", precision)\n",
    "    mlflow.log_metric(\"test_recall\", recall)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "    cm_df = pd.DataFrame(cm, index=dataset.label_encoder.classes_, columns=dataset.label_encoder.classes_)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    img_file = os.path.join(img_path, f\"confusion_matrix_{run_name}.png\")\n",
    "    cm_file = os.path.join(results_dir, f\"confusion_matrix_{run_name}.csv\")\n",
    "\n",
    "    plt.savefig(img_file)\n",
    "    cm_df.to_csv(cm_file)\n",
    "\n",
    "    mlflow.log_artifact(img_file)\n",
    "    mlflow.log_artifact(cm_file)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    # Save feature maps and labels to file\n",
    "    if cnn:\n",
    "        feature_maps_file = os.path.join(img_path, f\"feature_maps_{run_name}.pt\")\n",
    "        torch.save((feature_maps, y_true_test, y_pred_test), feature_maps_file)\n",
    "    # mlflow.log_artifact(feature_maps_file, artifact_path=\"feature_maps\")\n",
    "\n",
    "    return y_true_test, y_pred_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN with evoked response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loader, val_loader, test_loader, dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_DIR_EV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_val_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIN_MEMORY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEQ_LENGTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/01.Study/01.MSc/01.Thesis/02.AIThesis/Brain-Structures-Classification-from-iEEG/src/utils.py:37\u001b[0m, in \u001b[0;36mget_loaders\u001b[0;34m(data_dir, batch_size, num_workers, pin_memory, with_val_loader, test_size, val_size, seq_length, model_type)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_loaders\u001b[39m(data_dir: \u001b[38;5;28mstr\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m, num_workers: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m     15\u001b[0m                 pin_memory: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, with_val_loader: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     16\u001b[0m                 test_size: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, val_size: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, seq_length: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m, \n\u001b[1;32m     17\u001b[0m                 model_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[DataLoader, DataLoader], Tuple[DataLoader, DataLoader, DataLoader]]:\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Creates data loaders for training, testing, and optionally validation from IEEG dataset.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        Returns train and test data loaders. If `with_val_loader` is True, also returns a validation data loader.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mIeegDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal dataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([dataset[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))])\n",
      "File \u001b[0;32m~/Documents/01.Study/01.MSc/01.Thesis/02.AIThesis/Brain-Structures-Classification-from-iEEG/src/ieeg_dataset.py:38\u001b[0m, in \u001b[0;36mIeegDataset.__init__\u001b[0;34m(self, data_dir, seq_length, model_type)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_encoder\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Load data from CSV files\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels)\u001b[38;5;241m.\u001b[39msqueeze(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "File \u001b[0;32m~/Documents/01.Study/01.MSc/01.Thesis/02.AIThesis/Brain-Structures-Classification-from-iEEG/src/ieeg_dataset.py:53\u001b[0m, in \u001b[0;36mIeegDataset._load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, math\u001b[38;5;241m.\u001b[39mfloor(df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_length)):\n\u001b[1;32m     52\u001b[0m     signal_window \u001b[38;5;241m=\u001b[39m df[column]\u001b[38;5;241m.\u001b[39mvalues[idx \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_length : (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_length]\n\u001b[0;32m---> 53\u001b[0m     class_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mappend(signal_window)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mappend(class_label)\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/sklearn/utils/_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/sklearn/utils/_encode.py:164\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_map_to_integer\u001b[39m(values, uniques):\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Map values based on its position in uniques.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     table \u001b[38;5;241m=\u001b[39m \u001b[43m_nandict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mval\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/sklearn/utils/_encode.py:149\u001b[0m, in \u001b[0;36m_nandict.__init__\u001b[0;34m(self, mapping)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_nandict\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Dictionary with support for nans.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mapping):\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(mapping)\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, dataset = get_loaders(data_dir=DATA_DIR_EV, with_val_loader=True, \n",
    "                                                             batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                                             pin_memory=PIN_MEMORY, test_size=0.15, \n",
    "                                                             seq_length=SEQ_LENGTH, model_type=\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Baseline_ANN(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=2000, out_features=4096, bias=True)\n",
       "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (5): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation): ReLU()\n",
       "  (output_layer): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layers = [4096,4096,2048,2048,1024,1024]\n",
    "model = Baseline_ANN(INPUT_SIZE, NUM_CLASSES, hidden_layers=hidden_layers, dropout=0.3).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 155.320 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'Model size: {get_model_size(model):.3f} MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train_loader\n",
      "train_loader - Batch 0: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 1: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 2: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 3: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 4: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 5: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 6: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 7: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 8: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 9: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 10: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 11: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 12: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 13: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 14: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 15: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 16: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 17: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 18: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 19: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 20: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 21: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 22: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 23: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 24: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 25: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 26: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 27: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 28: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 29: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 30: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 31: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 32: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 33: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 34: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 35: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 36: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 37: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 38: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 39: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 40: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 41: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 42: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 43: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 44: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 45: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 46: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 47: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 48: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 49: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 50: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 51: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 52: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 53: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 54: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 55: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 56: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 57: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 58: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 59: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 60: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 61: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 62: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 63: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 64: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 65: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 66: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 67: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 68: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 69: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 70: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 71: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 72: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 73: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 74: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 75: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 76: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 77: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 78: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 79: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 80: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 81: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 82: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 83: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 84: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 85: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 86: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 87: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 88: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 89: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 90: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 91: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 92: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 93: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 94: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 95: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 96: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 97: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 98: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 99: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 100: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 101: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 102: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 103: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 104: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 105: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 106: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 107: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 108: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 109: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 110: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 111: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 112: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 113: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 114: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 115: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 116: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 117: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 118: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 119: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 120: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 121: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 122: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 123: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 124: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 125: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 126: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 127: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 128: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 129: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 130: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 131: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 132: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 133: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 134: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 135: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 136: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 137: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 138: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 139: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 140: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 141: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 142: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 143: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 144: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 145: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 146: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 147: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 148: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 149: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 150: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 151: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 152: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 153: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 154: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 155: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 156: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 157: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 158: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 159: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 160: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 161: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 162: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 163: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 164: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 165: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 166: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 167: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 168: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 169: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 170: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 171: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 172: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 173: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 174: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 175: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 176: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 177: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 178: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 179: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 180: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 181: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 182: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 183: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 184: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 185: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 186: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 187: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 188: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 189: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 190: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 191: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 192: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 193: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 194: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 195: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 196: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 197: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 198: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 199: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 200: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 201: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 202: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 203: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 204: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 205: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 206: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 207: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 208: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 209: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 210: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 211: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 212: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 213: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 214: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 215: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 216: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 217: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 218: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 219: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 220: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 221: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 222: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 223: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 224: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 225: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 226: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 227: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 228: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 229: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 230: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 231: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 232: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 233: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 234: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 235: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 236: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 237: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 238: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 239: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 240: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 241: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 242: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 243: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 244: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 245: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 246: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 247: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 248: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 249: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 250: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 251: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 252: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 253: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 254: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 255: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 256: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 257: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 258: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 259: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 260: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 261: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 262: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 263: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 264: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 265: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 266: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 267: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 268: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 269: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 270: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 271: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 272: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 273: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 274: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 275: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 276: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 277: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 278: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 279: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 280: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 281: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 282: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 283: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 284: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 285: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 286: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 287: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 288: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 289: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 290: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 291: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 292: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 293: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 294: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 295: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 296: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 297: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 298: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 299: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 300: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 301: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 302: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 303: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 304: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 305: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 306: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 307: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 308: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 309: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 310: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 311: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 312: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 313: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 314: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 315: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 316: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 317: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 318: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 319: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 320: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 321: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 322: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 323: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 324: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 325: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 326: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 327: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 328: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 329: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 330: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 331: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 332: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 333: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 334: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 335: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 336: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 337: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 338: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 339: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 340: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 341: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 342: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 343: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 344: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 345: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 346: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 347: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 348: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 349: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 350: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 351: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 352: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 353: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 354: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 355: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 356: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 357: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 358: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 359: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 360: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 361: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 362: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 363: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 364: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 365: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 366: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 367: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 368: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 369: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 370: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 371: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 372: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 373: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 374: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 375: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 376: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 377: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 378: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 379: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 380: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 381: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 382: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 383: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 384: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 385: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 386: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 387: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 388: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 389: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 390: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 391: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 392: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 393: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 394: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 395: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 396: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 397: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 398: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 399: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 400: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 401: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 402: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 403: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 404: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 405: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 406: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 407: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 408: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 409: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 410: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 411: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 412: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 413: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 414: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 415: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 416: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 417: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 418: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 419: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 420: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 421: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 422: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 423: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 424: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 425: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 426: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 427: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 428: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 429: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 430: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 431: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 432: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 433: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 434: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 435: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 436: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "train_loader - Batch 437: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "Checking test_loader\n",
      "test_loader - Batch 0: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 1: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 2: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 3: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 4: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 5: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 6: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 7: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 8: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 9: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 10: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 11: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 12: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 13: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 14: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 15: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 16: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 17: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 18: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 19: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 20: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 21: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 22: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 23: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 24: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 25: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 26: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 27: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 28: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 29: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 30: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 31: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 32: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 33: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 34: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 35: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 36: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 37: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 38: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 39: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 40: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 41: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 42: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 43: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 44: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 45: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 46: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 47: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 48: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 49: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 50: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 51: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 52: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 53: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 54: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 55: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 56: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 57: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 58: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 59: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 60: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 61: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 62: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 63: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 64: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 65: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 66: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 67: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 68: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 69: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 70: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 71: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 72: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 73: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 74: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 75: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 76: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 77: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 78: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 79: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 80: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 81: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 82: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 83: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "test_loader - Batch 84: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "Checking val_loader\n",
      "val_loader - Batch 0: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 1: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 2: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 3: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 4: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 5: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 6: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 7: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 8: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 9: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 10: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 11: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 12: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 13: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 14: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 15: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 16: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 17: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 18: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 19: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 20: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 21: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 22: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 23: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 24: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 25: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 26: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 27: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 28: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 29: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 30: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 31: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 32: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 33: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 34: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 35: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 36: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 37: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 38: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 39: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 40: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 41: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 42: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 43: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 44: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 45: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 46: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n",
      "val_loader - Batch 47: inputs shape = torch.Size([64, 2000]), labels shape = torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for loader_name, loader in zip(['train_loader', 'test_loader', 'val_loader'], [train_loader, test_loader, val_loader]):\n",
    "    print(f\"Checking {loader_name}\")\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        print(f\"{loader_name} - Batch {i}: inputs shape = {inputs.squeeze(0).shape}, labels shape = {labels.flatten().shape}\")\n",
    "        if inputs.shape[0] != 64:\n",
    "            print(f\"Warning: {loader_name} - Batch {i} has a different batch size: {inputs.shape[0]}, {labels.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/14', creation_time=1718790684663, experiment_id='14', last_update_time=1718790684663, lifecycle_stage='active', name='SECOND_IEEG_MODELS_COMP_FINAL', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/19 12:59:21 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898a0fb9679c498b856fbbbda5dc4bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17911a65b0dd46da8f324723b56bbaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9f39f70e20458b8c1eac405ce017dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a2d967ad7a432aa8f969a41675850d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b24d4aa6005433c881bcec3645bfa22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbac66f25ba441729fad3263f8c2006e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051c7b9c262e4fbe8309338aba26de11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25700f6e56ba402b8d8e92ebc52dbe0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916dbc0ec2a649cba8096d7dc4d1179b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb4a96c9c0343a88f8547e6550beee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae23ec0f2a2b4eeb89f16dcdbd5f7846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090ea7b5bcbf4f6e8aa8f93ddffe6579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dc87574db347d5945ede3040fe71b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6568fe09b7f34e2cab87bbdc50e1eb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7def263c07421198149adb5ea58b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3247b7a82a47b29a761cc32c43b1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400be4e918224d6899e234c0f99b3bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9f7f5e7bf74b9b9dd6e875a7f5d6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a580720fbb604484915aa9a9c7615ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6080a681d584af9bc34c73dafc43ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28c1451ed254d559e0b3579fa765ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136a73e6faf2412c8ec481162aa14435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb010bac86a4f8d8ebb4bcc8345680f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d3d95601c94ea480646c16aa092ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae637adaf65410e88a85a4ad929031d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff0e0257bb146cea158546fb3ee4939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd5053dc53a4cb681a15acee30ef2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbeca493f0543a69eb1ec3258e8c0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301cb9cb42834571918ec29db7d3f4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f985d026d74047b7ba4ec50ec8e53776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1a9af66d0d4668bb8392f5a07c7363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7738de58a99e46fca563cd2b7879fa67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276642c5f1624965b14c48cc7d2a4cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05508ac8e86b48beb2dcc1bb85008e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8ef06ab4824a4d82a5307b9a2af6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc05bbb78464e23b7a6a6966322be97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016a72fa8d75469caa2243c695852b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91df948ecb65443b8ad8bf8a6fde65b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91f9b979830483a8462b1f80ebf7485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b023c53c429e41ff90509eeabd71fff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b3d41b00b34166832cb7860bf47292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5862afa18b426c8bf3b042aaa3e27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208cc47c9211416eb16357dd8e4c001d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e08d4a997734381b9cd126d2b58b650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0ec925c16946eb9185c9741e9274c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fed8562bb2748c78b3d8d59792ca4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c4ca70b03f4c0687416b7770c4731d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86adf9f2622b44cc91ed59975be5da32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ea3bd7a5764f94881eecb4e4a541d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fedea356deb4b84ba69b35fd69b86e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50:   0%|          | 0/438 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0a1a6a616144c398fa5f7a19c97624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/85 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.77%\n",
      "Precision: 0.7552, Recall: 0.7688, F1 Score: 0.7599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/19 13:11:20 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/19 13:11:20 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"ANN_with_er\"\n",
    "model_name = \"ANN_baseline_wr\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=40, cnn=False)\n",
    "    _, _ = evaluate_model(model, test_loader, dataset, DEVICE, results_dir=results_dir,img_path='../plots', run_name=run_name)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 29316\n",
      "Train indices length: 24918, Test indices length: 4398\n",
      "Train indices after val split: 22426, Val indices: 2492\n",
      "Train dataset length: 22426, Val dataset length: 2492, Test dataset length: 4398\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, dataset = get_loaders(data_dir=DATA_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, test_size=0.15, seq_length=SEQ_LENGTH, model_type=\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Baseline_ANN(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=2000, out_features=4096, bias=True)\n",
       "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (5): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation): ReLU()\n",
       "  (output_layer): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layers = [4096,4096,2048,2048,1024,1024]\n",
    "model = Baseline_ANN(INPUT_SIZE, NUM_CLASSES, hidden_layers=hidden_layers, dropout=0.3).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 155.320 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'Model size: {get_model_size(model):.3f} MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/14', creation_time=1718790684663, experiment_id='14', last_update_time=1718790684663, lifecycle_stage='active', name='SECOND_IEEG_MODELS_COMP_FINAL', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/19 13:16:23 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff31774f7d24b948f5740a825a6c7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09aa5f9b1e6463ab58e5ca7abacbb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23ee6f224614131bf3ee6f40f092984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40989817fcf94dbe94a8f568ad98e7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fdb04ec4604440932e5c95b9aa93ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716afa0c1a5a41ada0e4aeb6dd790e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f443ded692746a280e1fc4bd12382b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a712c4205ef4422d920e64886285d8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33973730ae248929cf26e17bf2628f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffd5d076a82461e8c34d6c966f5a873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94386671521d4c1c9e17d38d422148d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa1af8b64c94e3db2faeb7ffc54292c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2562f0f2a24abebe087ed6763ec89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4fd00dd23b41439229677f817def9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca1ebe96456410f927c53271f5277ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fe96f6fb5349538575a35c80d5103a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f729318841405fba3c5d305dcf35d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9872caa1714344e59c8bd4906d7c8869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc39d06185e4f1a8ee4b411b463c22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab35f7af352244d082dd2bd4da8e33cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cca3c81baf5441fbed9c1e7d30a1193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff65b8e74dc48b980d862c0dd252677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727157f683844846814ffef0fbe66acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b349602346bc40e584b2dadacf528160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e7e028c9a54bb6930e666b3d70d0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25ff4170bc841079888cc7457a47092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f98e0bd0f645a4b9bcdc984dbb53f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7a2efba9f94e34b82b9c6235e1f293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ba777caeb94ae4a15ae05d72ce3189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9619be85ab415495a0cbf8b279311a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a66d9bd3e6248f1bc4b3004a10d376d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf5a61c2e8b4d0eb1e66e2ddf06a810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312c75b24fb14ef9991febfee475dfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36369e4ccabf4c8980aba064c3a88e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8955eb2ce54ee8ae3e9be0ccb30a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237e493d63404cc2b9a2d523ecb65c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b082cd88894ee8aa6d2e96090ea89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a787b2b349b6449fb81f70572abfe360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb7e6d5d8f749d1a92be3f78cdff7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f32cebcf794f64bb225e21f79e24b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2635dd53824d04b6e3a18cf1da0092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5cd26a1be44d7a8c6c9c5315f4ddcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32052503832945dc9de8837780d16cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2307f7e1a8ba4829886b37301f7ada42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2de435888e4e7daff98852f3d7745e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b54ace701b04a7fa7c07fde79fadcfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fecb6476814f8f9e5f697da21e0639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e92c381262435cb412e267da9db658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5d4e0f88b246df99e1b8c7ab7d47bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9e52b0527c43f9afabe88e8caae2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff992b6b19004ee99e66b8ca9f56a1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/68 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.72%\n",
      "Precision: 0.7070, Recall: 0.7171, F1 Score: 0.7112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/19 13:25:44 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/19 13:25:44 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"ANN\"\n",
    "model_name = \"ANN_baseline\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=40, cnn=False)\n",
    "    _,_ = evaluate_model(model, test_loader, dataset, DEVICE, results_dir=results_dir,img_path='../plots', run_name=run_name)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 29316\n",
      "Train indices length: 24918, Test indices length: 4398\n",
      "Train indices after val split: 22426, Val indices: 2492\n",
      "Train dataset length: 22426, Val dataset length: 2492, Test dataset length: 4398\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, dataset = get_loaders(data_dir=DATA_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, test_size=0.15, seq_length=SEQ_LENGTH, model_type=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 252.997 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_Ieeg_Model(\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (bn_layers): ModuleList(\n",
       "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (activation): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=64000, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_Ieeg_Model(SEQ_LENGTH, NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/14', creation_time=1718790684663, experiment_id='14', last_update_time=1718790684663, lifecycle_stage='active', name='SECOND_IEEG_MODELS_COMP_FINAL', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/19 17:34:51 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0867538e0a4076954bc057ade61dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6ff05b37a04c27b1ddf3942728fdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3f88a2dcff496b92322c46398c751b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f095241585e74e4bb9dfc850f88e9723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c458543af7fa44ef8648de310d61c0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92bd206a9d5475c81e71b1a2255076c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185aa93e4046415f9a7ff9b15936a0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bf005691c94f639afe901a7c7c32c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ad3b2947ed4f3d9b09483f50d388b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88b8148a9cb48e1b916d88315ff015d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cd5305bd0341b391c3e571c0d65627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267bc8ce566449cba6fa648847ea394d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4297f9dc96d2486396fa40142e9f4629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe7a34aacd34a6eab4764b42e0a433a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29af174caac142cea631344401e4ab09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a697fcda52564dc38a3a4b34abcf523b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfdf618d209429dab89ddb96e176a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bad850ec4f446d994b92e41a6cc1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8128e01166542d1a2266182439c4845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2694c9e4b8b42fd962f1c51e2e0ffc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7f67b776f44351bafe6d77a85cc86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f537d77824540f194540bf52ff1962c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d413f677ba4f458e9be35cd4deb085b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88989f2a43204e76bc0fd26135940c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e448879043c417a92b0e8cbb43bf43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b50e9a9775413a933ed1689856402b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4edfc01a8dd4430a3396217107ff87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c306de76b0e644a59a09768d9a2a5fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe3d64dc55c417b9475bc057b216cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c253da2bf04431b6266898527e75b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180f3dfa460b4814bc1b07ba88fde2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b739bb330e64532a355af9d651d1dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c21f9c9aaf24deab75e6b379db1c329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fa68c30aca489d9b0f4f306e572c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b2a3e6e5ff42ae965a26f167c2dbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6386c33e26e84b5bad3e33144718a19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0be7e5eb2d847719a83d13791cbbbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6b0a8a84ae47d493ed79425c055495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd2fdc84d0d4bf494c08b7118561f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a05ffe29ca481d9d4b301c0a1812c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c82724df33c4259903375b72a8231ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b378ca92bb1348b1a6fb2be7c4e6b7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e2f51efaeb4051a0ea5a7348843fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a151eaafbca4096a02a5e5f2e1946b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7c4e6e70114974a0a819401310a929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8a00905b774e5ba2478a8336186b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb63e0a5f4149fda92735fbd144f682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1a12d356df4eb5a1c5af087abb7445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d0789b10424d6b91d89c1f0635dcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cbbbbff39a40569feb98b0976fae05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86cb9d6e7bf45abb8c6a764b1b006f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/68 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.96%\n",
      "Precision: 0.9624, Recall: 0.9614, F1 Score: 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/19 17:50:51 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/19 17:50:51 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"CNN\"\n",
    "model_name = \"CNN\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=50, cnn=True)\n",
    "    _,_ = evaluate_model(model, test_loader, dataset, DEVICE, \n",
    "                         results_dir=results_dir,\n",
    "                         img_path='../plots', \n",
    "                         run_name=run_name,\n",
    "                         cnn=True)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONV Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 205212\n",
      "Train indices length: 174430, Test indices length: 30782\n",
      "Train indices after val split: 156987, Val indices: 17443\n",
      "Train dataset length: 156987, Val dataset length: 17443, Test dataset length: 30782\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, dataset = get_loaders(data_dir=DATA_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, test_size=0.15, seq_length=SEQ_LENGTH, model_type=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader - Batch 0: inputs shape = torch.Size([200, 1, 300]), labels shape = torch.Size([200])\n",
      "test_loader - Batch 0: inputs shape = torch.Size([200, 1, 300]), labels shape = torch.Size([200])\n",
      "val_loader - Batch 0: inputs shape = torch.Size([200, 1, 300]), labels shape = torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "for loader_name, loader in zip(['train_loader', 'test_loader','val_loader'], [train_loader, test_loader, val_loader]):\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        print(f\"{loader_name} - Batch {i}: inputs shape = {inputs.shape}, labels shape = {labels.shape}\")\n",
    "        if i == 0:  # Only print the first batch for brevity\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_size = SEQ_LENGTH  # Use the sequence length provided by your dataset\n",
    "num_classes = 4  # Number of classes for classification\n",
    "transformer_dim = 512  # Smaller transformer dimension\n",
    "num_heads = 8  # Fewer attention heads\n",
    "transformer_depth = 7  # Fewer transformer layers\n",
    "fc_neurons = [512, 256]  # Reduced fully connected layer sizes\n",
    "fc_transformer = 512\n",
    "dropout = 0.3  # Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvTransformerModel(\n",
    "    input_size=input_size,\n",
    "    num_classes=num_classes,\n",
    "    transformer_dim=transformer_dim,\n",
    "    num_heads=num_heads,\n",
    "    transformer_depth=transformer_depth,\n",
    "    fc_neurons=fc_neurons,\n",
    "    fc_transformer=fc_transformer,\n",
    "    dropout=dropout,\n",
    "    activation=nn.GELU()\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 91.161 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvTransformerModel(\n",
       "  (conv_embedding_stem): ConvEmbeddingStem(\n",
       "    (conv1): Conv1d(1, 256, kernel_size=(10,), stride=(2,), padding=(4,), bias=False)\n",
       "    (act1): GELU(approximate='none')\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (act2): GELU(approximate='none')\n",
       "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (act3): GELU(approximate='none')\n",
       "    (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (transformer_blocks): ModuleList(\n",
       "    (0-6): 7 x MultiheadSelfAttentionBlock(\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc_transformer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation): GELU(approximate='none')\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion =  nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/14', creation_time=1718790684663, experiment_id='14', last_update_time=1718790684663, lifecycle_stage='active', name='SECOND_IEEG_MODELS_COMP_FINAL', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/23 19:36:25 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7405b865a7c24fbaa70dc67819c0e1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/784 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4082399a83c94a18a0172a77b8414fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/153 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.93%\n",
      "Precision: 0.9331, Recall: 0.9342, F1 Score: 0.9331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/23 19:41:35 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/23 19:41:35 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"run_CNN_TNN_sl500\"\n",
    "model_name = \"CNN_TNN_sl500\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=10, cnn=False)\n",
    "    _,_ = evaluate_model(model, test_loader, dataset, DEVICE, \n",
    "                         results_dir=results_dir,\n",
    "                         img_path='../plots', \n",
    "                         run_name=run_name,\n",
    "                         cnn=False)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 122150\n",
      "Train indices length: 103827, Test indices length: 18323\n",
      "Train indices after val split: 93444, Val indices: 10383\n",
      "Train dataset length: 93444, Val dataset length: 10383, Test dataset length: 18323\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, dataset = get_loaders(data_dir=DATA_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, test_size=0.15, seq_length=SEQ_LENGTH, model_type=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 65.848 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ParallelCNNLSTMModel(\n",
       "  (cnn_head): CNN_Head(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (3): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "    (bn_layers): ModuleList(\n",
       "      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(1, 64, num_layers=3, batch_first=True)\n",
       "  (fc_lstm): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=16000, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ParallelCNNLSTMModel(input_size=SEQ_LENGTH, \n",
    "                            num_classes=NUM_CLASSES,\n",
    "                            input_size_lstm=1,\n",
    "                            # conv_filters=[64,128,256],\n",
    "                            # fc_neurons=[1024,128],\n",
    "                            # lstm_hidden_size=64,\n",
    "                            lstm_num_layers=3\n",
    "                        ).to(DEVICE)\n",
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion =  nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "    if experiment.lifecycle_stage == 'deleted':\n",
    "        mlflow.tracking.MlflowClient().restore_experiment(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/14', creation_time=1718790684663, experiment_id='14', last_update_time=1718790684663, lifecycle_stage='active', name='SECOND_IEEG_MODELS_COMP_FINAL', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/20 20:16:46 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce120e5573f4dd59161ca44105536e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0834df5f6cfb4fbd8a914a2c6402870d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202ddac28f98421d9ff8c0d9557a3a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f80ccd23b1c436cb60586c7742c85cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786c9cca42ce41ca9de261e4d798c1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc182e8e60614ea4a7c4f648b01fc2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1a5127f7b44ce9a8a090c9acbd0b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3fb53b4512403cb41ff073b946246c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca695b95ce104dfd984f7a5a37e1670f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8156ce40e0419c9faf908223450f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a95cc0457d413894c2a49292ababf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3180da644d94f76b2d7d364fdee190c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a8455fc69c40899e5ba6709a47171e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427b83c794ea42b386368c75523eac28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5eb6b6f21646e9a0e1956de9f2009e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9f496cde034086b7772856b16675e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f1abee0fac40479c887a883b911e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db01ab9fec9f43bc91ccd71ff6dbe384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0df6b775d04b8c99e6ca1a8824e020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8bccda12a0436eae069bc393f96e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80a6c0176be444080a35bfe618aa7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14aa90c92d6440eb9ae117be80b420b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0689085d3be64afc9e813b24212fba7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99c560712de4e6f8bde9894d84c3268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946dbaa1322940a1ab7a4b9b9b49b0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48708542979b4a0fb31c8a2540fffcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188a44f6af9d4ce5b78e1ef8efa3e3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc37bf5e8cf94a70a7eb32c50375fc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c0b1c084d743f8867a29735070bf11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a286b7cd9e42bcbd977fc441e98423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabcb4970bbf4f24b734f7e998bb8574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4a2a777e244806ae8c62a29f00b1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab071d9ce214ceeb307efa9afa2839f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea93ce7e895439185ca4c033117a06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeeeb33db75423db377562e503d5978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9bb67b697d44ff833a742fead89265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a89bb6ba0444618e0c606cca0e0139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2c0b393dc34927af4f30e1aacb2bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50:   0%|          | 0/1460 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 38 due to no improvement in validation loss.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bf412f9d1743be8e2ea043dc31704d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/286 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielcrovo/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 0.97%\n",
      "Precision: 0.9690, Recall: 0.9689, F1 Score: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/20 21:03:59 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/20 21:03:59 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and Evaluate the Model with MLflow\n",
    "run_name = \"P_CNN_LSTM_Experiment_sl500\"\n",
    "model_name = \"P_CNN_LSTM_sl500\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=10, cnn=False)\n",
    "    _,_ = evaluate_model(model, test_loader, dataset, DEVICE, \n",
    "                         results_dir=results_dir,\n",
    "                         img_path='../plots', \n",
    "                         run_name=run_name,\n",
    "                         cnn=False)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 29316\n",
      "Train indices length: 24918, Test indices length: 4398\n",
      "Train indices after val split: 22426, Val indices: 2492\n",
      "Train dataset length: 22426, Val dataset length: 2492, Test dataset length: 4398\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, dataset = get_loaders(data_dir=DATA_DIR, with_val_loader=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                        pin_memory=PIN_MEMORY, test_size=0.15, seq_length=SEQ_LENGTH, model_type=\"seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 40.135 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM_Ieeg_Model(\n",
       "  (activation): ReLU()\n",
       "  (lstm): LSTM(1, 380, num_layers=8, batch_first=True, dropout=0.1)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=380, out_features=2048, bias=True)\n",
       "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=4, bias=True)\n",
       "  (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_Ieeg_Model(device=DEVICE,\n",
    "                        input_size=1, \n",
    "                        num_classes=NUM_CLASSES, \n",
    "                        lstm_layers=8, \n",
    "                        lstm_h_size=380,\n",
    "                        fc_neurons=[2048,512], \n",
    "                        bidirectional=False).to(DEVICE)\n",
    "print(f'Model size: {get_model_size(model):.3f} MB')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion =  nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/14', creation_time=1718790684663, experiment_id='14', last_update_time=1718790684663, lifecycle_stage='active', name='SECOND_IEEG_MODELS_COMP_FINAL', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/22 18:54:13 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21d9622e052472290031ad4fb3274b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e208463cdb0f4e7c8424da015d8127ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90298745d9e4d85ac491f21e22aa8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/350 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/22 19:06:38 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/22 19:06:38 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_dict(dataset\u001b[38;5;241m.\u001b[39mget_class_mapping(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_mapping.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train and Evaluate the Model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_checkpoint_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHECKPOINTS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m _,_ \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, dataset, DEVICE, \n\u001b[1;32m     19\u001b[0m                      results_dir\u001b[38;5;241m=\u001b[39mresults_dir,\n\u001b[1;32m     20\u001b[0m                      img_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../plots\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     21\u001b[0m                      run_name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m     22\u001b[0m                      cnn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Log the model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 61\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, num_epochs, device, save_checkpoint_interval, early_stopping_patience, checkpoint_dir, results_dir, accumulation_steps, cnn, model_name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[1;32m     59\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m     62\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Reset gradients after updating weights\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/amp/grad_scaler.py:453\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    451\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 453\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/amp/grad_scaler.py:350\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/ieeg/lib/python3.12/site-packages/torch/amp/grad_scaler.py:350\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_name = \"run_2_LSTM_2000\"\n",
    "model_name = \"LSTM_2000\"\n",
    "results_dir = \"../models/results\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"input_size\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "    mlflow.log_dict(dataset.get_class_mapping(), \"class_mapping.json\")\n",
    "\n",
    "    # Train and Evaluate the Model\n",
    "    train_model(model, train_loader,val_loader, optimizer, criterion, NUM_EPOCHS, DEVICE, \n",
    "                save_checkpoint_interval=10, checkpoint_dir=CHECKPOINTS_PATH, \n",
    "                model_name=model_name, early_stopping_patience=10, cnn=False)\n",
    "    _,_ = evaluate_model(model, test_loader, dataset, DEVICE, \n",
    "                         results_dir=results_dir,\n",
    "                         img_path='../plots', \n",
    "                         run_name=run_name,\n",
    "                         cnn=False)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
